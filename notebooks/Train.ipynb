{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5eb761b0-c37e-4079-937a-e9f7ac9bd566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "from datetime import datetime\n",
    "\n",
    "current_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "parent_dir = os.path.join(current_dir, '..', \"utils\")\n",
    "sys.path.append(parent_dir)\n",
    "parent_dir = os.path.join(current_dir, '..', \"models\")\n",
    "sys.path.append(parent_dir)\n",
    "from data_segment import save_all_data\n",
    "\n",
    "from dataset import load_data\n",
    "from resnet import resnet\n",
    "from load_config import load_config_yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "211bd9ae-815d-40df-86d8-6b21f93de048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_hat, y):\n",
    "    \"\"\"计算正确预测的数量\"\"\"\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = torch.argmax(y_hat, dim=1)\n",
    "    cmp = y_hat == torch.argmax(y, dim=1)\n",
    "    return float(cmp.type(y.dtype).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40777cfc-9580-42e8-91a9-3db5f2699bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_acc_loss(net, data_iter, loss, device=None):\n",
    "    if isinstance(net, nn.Module):\n",
    "        net.eval()  # 设置为评估模式\n",
    "        if not device:\n",
    "            device = next(iter(net.parameters())).device\n",
    "    # 正确预测的数量, 测试损失之和, 总预测的数量\n",
    "    metric = d2l.Accumulator(3)\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(X, list):\n",
    "                # BERT微调所需的\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = net(X)\n",
    "            metric.add(accuracy(y_hat, y), loss(y_hat, y) * X.shape[0], y.shape[0])\n",
    "    return metric[0] / metric[2], metric[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cad5cc-50a9-4fe3-b5a9-e990546452fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_iter, test_iter, num_epochs, learning_rate, patience, devices, logger, weights_save_parent_path):\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weights)\n",
    "    \n",
    "    # 在多个GPU上并行训练模型\n",
    "    net = nn.DataParallel(net, device_ids=devices).to(devices[0])\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    timer, num_batches = d2l.Timer(), len(train_iter)\n",
    "\n",
    "    best_test_loss = float('inf')\n",
    "    best_test_loss_epoch = 0\n",
    "    current_patience = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # 训练损失之和, 训练准确率之和, 样本数\n",
    "        metric = d2l.Accumulator(3)\n",
    "        net.train()\n",
    "        for i, (X, y) in enumerate(train_iter):\n",
    "            timer.start()\n",
    "            optimizer.zero_grad()\n",
    "            X, y = X.to(devices[0]), y.to(devices[0])\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                metric.add(l * X.shape[0], accuracy(y_hat, y), X.shape[0])\n",
    "            timer.stop()\n",
    "            train_l = metric[0] / metric[2]\n",
    "            train_acc = metric[1] / metric[2]\n",
    "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
    "                logger.record_logs(f'epoch: {epoch + 1}, data iter: {i + 1}, train loss: {train_l:.3f}, train acc: {train_acc:.3f}\\n')\n",
    "        test_acc, test_loss = evaluate_acc_loss(net, test_iter, loss)\n",
    "        logger.record_logs(f'epoch: {epoch + 1}, test acc: {test_acc:.3f}\\n')\n",
    "        weights_save_path = os.path.join(weights_save_parent_path, f\"epoch_{epoch + 1}.pth\")\n",
    "        if (epoch + 1) % 5 == 0 or (epoch + 1) == num_epochs:\n",
    "            torch.save(net.state_dict(), weights_save_path)\n",
    "        if test_loss < best_test_loss:\n",
    "            best_test_loss = test_loss\n",
    "            best_test_loss_epoch = epoch + 1\n",
    "            current_patience = 0\n",
    "        else:\n",
    "            current_patience += 1\n",
    "            if current_patience >= patience:\n",
    "                logger.record_logs(f'Early stopping after {epoch} epochs.\\n', f'The best test loss occurs in the {best_test_loss_epoch} epoch.\\n')\n",
    "                break\n",
    "    logs = [f'loss {train_l:.3f}, train acc {train_acc:.3f}, test acc {test_acc:.3f}\\n',\n",
    "            f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec on {str(devices)}\\n']\n",
    "    logger.record_logs(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e01ed6-6b77-42b2-9d89-447c1a906265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "def copy_yaml_to_txt(yaml_file_path, txt_output_path):\n",
    "    try:\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
